N обработчиков
Горутины — легковесные объекты. Вполне можно запустить одновременно 10, 100 или 1000 штук. Но что, если исходных фраз будет 100 тысяч или миллион? Понятно, что реальная многозадачность все равно ограничена количеством ядер. Так что нет смысла впустую расходовать память на сотни тысяч горутин, если параллельно выполняться все равно будут только восемь (или сколько у вас там CPU).

Скажем, мы хотим, чтобы одновременно существовали только N say-горутин. Добиться этого поможет буферизованный канал. Идея следующая:

создаем канал с буфером размера N и заполняем его «токенами» (любыми значениями);
перед запуском горутина забирает токен из канала;
по завершении работы горутина возвращает токен в канал.
Таким образом, если в канале не осталось токенов, то очередная горутина не запустится и будет ждать, пока кто-нибудь вернет токен в канал. В результате одновременно запущены будут не более N горутин.

Вот как это может выглядеть при N = 2:
```go
func main() {
    phrases := []string{
        // ...
    }

    // пул идентификаторов для 2 горутин
    pool := make(chan int, 2)
    pool <- 1
    pool <- 2

    for _, phrase := range phrases {
        // получаем идентификатор из пула,
        // если есть свободные
        id := <-pool
        go say(pool, id, phrase)
    }

    // дожидаемся, пока все горутины закончат работу
    // (то есть все идентификаторы вернутся в пул)
    <-pool
    <-pool
}
```
Хорошая практика заключается в том, чтобы операции с семафорами располагались как можно ближе к операциям ввода-вывода, которые они регулируют.
```go
var tokens = make(chan struct{}, 20)

func crawl(url string) []string {
	fmt.Println(url)
	tokens <- struct{}{} // acquire a token
	list, err := links.Extract(url)
	<-tokens // release the token

	if err != nil {
		log.Print(err)
	}
	return list
}
```
